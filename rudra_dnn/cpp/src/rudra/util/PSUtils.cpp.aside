/*
 * PSUtils.cpp
 *
 *  Created on: Jul 19, 2015
 *      Author: weiz
 */

#include "rudra/param/PSUtils.h"
#include "rudra/Network.h"
#include "rudra/layers/Layer.h"
#include "rudra/math/Matrix.h"
#include "rudra/mpi/mpi_commons.h"
namespace rudra {
PSUtils::PSUtils(Network *nn, SolverType solverType) :
		nn(nn), networkSize(nn->networkSize), solverType(solverType), ts(1) {
	if(solverType == ADAGRAD){
		this->adagradNorm = new float[networkSize];
		memset(adagradNorm, 0, sizeof(float) * networkSize);
		for (int i = 0; i<networkSize; ++i){
			adagradNorm[i]=0;
		}
	}else{
		this->adagradNorm = NULL;
	}
	this->logFileName = "./psu.log";
	logStream.open(logFileName.c_str(), std::ios::trunc); //create the log file
	tsVecClock.clear();
}

void PSUtils::chkptAdaGrad(std::string adaFile){ // adaFile is gonna be a CSV file
    float *buf = new float[networkSize];
    memcpy(buf, this->adagradNorm, networkSize);
	Matrix<float> mat(1, networkSize, buf);
	mat.writeMat(adaFile);
	//delete [] buf;
}

void PSUtils::restartAdaGrad(std::string adaFile){
	Matrix<float> mat = Matrix<float>::readMat(adaFile);
	memcpy(this->adagradNorm, mat.buf, networkSize);
}

void PSUtils::applyUpdateAfterSum(float *gradMsg, size_t numLearner){
	if(numLearner == 0){
		memset(gradMsg, 0, sizeof(float) * networkSize);
		return;
	}

	// step 0, get the average
	float mult = 1.0f / (float) numLearner;
	#pragma omp parallel for
	for (size_t i = 0; i < this->networkSize; ++i) {
		gradMsg[i] *= mult;
	}
	if(solverType == ADAGRAD){
		this->adaNormalizeGradients(this->networkSize, this->adagradNorm, gradMsg);
	}
	this->nn->deserializeUpdates(gradMsg);

	// step3: directly apply
	for (int i = 0; i < this->nn->N; ++i) {
		this->nn->L[i]->applyUpdate();
	}
	// contract is that PSUtils will clearup gradMsg
	memset(gradMsg, 0, sizeof(float) * networkSize); // clear up gradMsg
	ts++;
	this->logTSVecPerUpdate(); // added 2015-08-26, record the gradient contributors' timestamp
}

void PSUtils:: adaNormalizeGradients(const size_t networkSize, float * adagradNorm, float * parameterUpdates){

	#pragma omp parallel for
	for (int i = 0; i < networkSize; i++){
		adagradNorm[i] += parameterUpdates[i]*parameterUpdates[i];
		parameterUpdates[i] *= (1.0f/sqrt(1 + adagradNorm[i]));
	}

/*#pragma omp parallel for
	for (int i = 0; i < networkSize; i++){
		adagradNorm[i] *= 0.9;
		adagradNorm[i] += 0.1*parameterUpdates[i]*parameterUpdates[i];
		parameterUpdates[i] *= (1.0f/sqrt(1 + adagradNorm[i]));
	}*/


}

long PSUtils:: getTS(){
	return this->ts;
}

void PSUtils::appendUpdateTSVec(float *gradOffSet){
	size_t i = 0;
	for(; i < GRAD_PADDING; i++){
		if(gradOffSet[i] == GRAD_TS_DELIMITER){
			break;
		}else{
			this->tsVecClock.push_back((int) gradOffSet[i]);
			//std::cerr<<"tsVecClock: "<<(int) gradOffSet[i]<<std::endl;
		}
	}
}

void PSUtils::logTSVecPerUpdate(){
	logStream<<this->ts<<"@ [ ";
	std::vector<int>::iterator vit = tsVecClock.begin();
	for(; vit != tsVecClock.end(); vit++){
		int _ts = *vit;
		logStream<<_ts<<" ";
	}
	logStream<<"]"<<std::endl;
	this->tsVecClock.clear(); // clearup the ts vector-clock
}

PSUtils::~PSUtils(){
	if(solverType == ADAGRAD){
		delete [] adagradNorm;
		adagradNorm = NULL;
	}
	logStream.close();
}
}
